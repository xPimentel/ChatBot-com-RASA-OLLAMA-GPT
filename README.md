# RasaGPT ğŸ¤–

RasaGPT Ã© um assistente de conversaÃ§Ã£o avanÃ§ado que combina o poder do framework Rasa com modelos de linguagem como ChatGPT (via API) e Ollama (localmente). Este projeto permite criar um chatbot com interface web elegante que pode:

- Processar intenÃ§Ãµes bÃ¡sicas de conversaÃ§Ã£o
- Conectar-se Ã  API do OpenAI para usar o ChatGPT
- Integrar-se ao Ollama para processamento local de IA
- Oferecer uma interface web responsiva e amigÃ¡vel

<img src="video_convertido.gif" alt="DescriÃ§Ã£o">

## ğŸ“‹ PrÃ©-requisitos

Antes de comeÃ§ar, vocÃª precisarÃ¡ ter instalado:

- Python (3.8 ou superior)
- Node.js e npm (para desenvolvimento frontend, opcional)
- Ollama (opcional, para processamento local de IA)

## ğŸš€ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/rasagpt.git
cd rasagpt
```

### 2. Configure um ambiente virtual Python

```bash
# Crie um ambiente virtual
python -m venv venv

# Ative o ambiente virtual
# No Windows
venv\Scripts\activate
# No macOS/Linux
source venv/bin/activate
```

### 3. Instale o Rasa e dependÃªncias

```bash
pip install rasa==3.6.2
pip install rasa-sdk==3.6.0
pip install openai requests
```

### 4. Configure a API do OpenAI (opcional, mas recomendado para usar o ChatGPT)

```bash
# No Windows
set OPENAI_API_KEY=sua-chave-api-aqui

# No macOS/Linux
export OPENAI_API_KEY=sua-chave-api-aqui

# Para tornar permanente, adicione ao seu arquivo .bashrc, .zshrc ou similar
```

### 5. Instale o Ollama (opcional, para processamento local de IA)

Siga as instruÃ§Ãµes oficiais de instalaÃ§Ã£o em [Ollama.ai](https://ollama.ai)

Depois de instalar o Ollama, baixe um modelo como o Llama 2:

```bash
ollama pull llama2
```

## âš™ï¸ ConfiguraÃ§Ã£o

### Treine o modelo Rasa

```bash
cd rasagpt
rasa train
```

Este comando cria um modelo com base nos dados de treinamento e configuraÃ§Ã£o em `data/` e `config.yml`.

## ğŸƒâ€â™‚ï¸ Executando o Projeto

Para execuÃ§Ã£o completa, vocÃª precisarÃ¡ iniciar trÃªs componentes:

### 1. Inicie o servidor de aÃ§Ãµes personalizadas

```bash
# Em um terminal
cd rasagpt
rasa run actions
```

### 2. Inicie o servidor Rasa principal

```bash
# Em outro terminal
cd rasagpt
rasa run --enable-api --cors "*"
```

### 3. Inicie a interface web

```bash
# Em um terceiro terminal
cd rasagpt/webtest
python -m http.server 8080
```

Agora, acesse http://localhost:8080 no seu navegador para interagir com o RasaGPT.

## ğŸ” Uso do Assistente

ApÃ³s iniciar todos os componentes, vocÃª poderÃ¡ conversar com o assistente atravÃ©s da interface web:

- Para conversa regular: Digite qualquer mensagem normalmente
- Para usar o ChatGPT: Digite `gpt: sua pergunta` ou `pergunte ao gpt: sua pergunta`
- Para usar o Ollama (IA local): Digite `ollama: sua pergunta` ou `pergunte ao ollama: sua pergunta`

Exemplos:
- "OlÃ¡, como vai?"
- "gpt: Explique a teoria da relatividade de Einstein"
- "ollama: Quais sÃ£o as melhores prÃ¡ticas para desenvolvimento Python?"

## ğŸ§© Estrutura do Projeto

```
rasagpt/
â”œâ”€â”€ .rasa/                   # Cache e arquivos de sessÃ£o Rasa
â”œâ”€â”€ actions/                 # AÃ§Ãµes personalizadas
â”‚   â””â”€â”€ actions.py           # CÃ³digo das aÃ§Ãµes personalizadas (ChatGPT/Ollama)
â”œâ”€â”€ data/                    # Dados de treinamento
â”‚   â”œâ”€â”€ nlu.yml              # Exemplos de intenÃ§Ãµes e entidades
â”‚   â”œâ”€â”€ rules.yml            # Regras de conversaÃ§Ã£o
â”‚   â””â”€â”€ stories.yml          # Fluxos de conversa
â”œâ”€â”€ models/                  # Modelos treinados do Rasa
â”œâ”€â”€ tests/                   # Testes automatizados
â”œâ”€â”€ webtest/                 # Interface web
â”‚   â”œâ”€â”€ index.html           # PÃ¡gina principal
â”‚   â”œâ”€â”€ style.css            # Estilos CSS
â”‚   â””â”€â”€ script.js            # LÃ³gica de frontend
â”œâ”€â”€ config.yml               # ConfiguraÃ§Ã£o do pipeline Rasa
â”œâ”€â”€ credentials.yml          # ConfiguraÃ§Ãµes dos canais
â”œâ”€â”€ domain.yml               # DefiniÃ§Ãµes de intenÃ§Ãµes, aÃ§Ãµes e respostas
â””â”€â”€ endpoints.yml            # ConfiguraÃ§Ã£o de endpoints
```

## ğŸ“ Personalizando o Assistente

### Adicionando novas intenÃ§Ãµes

Para adicionar novas intenÃ§Ãµes, edite o arquivo `data/nlu.yml`:

```yaml
nlu:
  - intent: nova_intencao
    examples: |
      - exemplo 1
      - exemplo 2
      - exemplo 3
```

### Adicionando novas respostas

Para adicionar novas respostas, edite o arquivo `domain.yml`:

```yaml
responses:
  utter_nova_resposta:
    - text: "Esta Ã© uma nova resposta"
```

### Criando novas regras ou histÃ³rias

Para adicionar comportamentos, edite `data/rules.yml` ou `data/stories.yml`.

### Treinando novamente

ApÃ³s fazer alteraÃ§Ãµes, treine novamente o modelo:

```bash
rasa train
```

## ğŸ”§ SoluÃ§Ã£o de Problemas

### CORS (Cross-Origin Resource Sharing)

Se encontrar erros de CORS, verifique:

1. O arquivo `credentials.yml` estÃ¡ configurado corretamente:
```yaml
rest:
  url: http://localhost:5005/webhooks/rest/webhook
  cors: "*"
```

2. Inicie o Rasa com a flag `--cors`:
```bash
rasa run --enable-api --cors "*"
```

### API do OpenAI

Se o ChatGPT nÃ£o estiver funcionando:

1. Verifique se a variÃ¡vel de ambiente `OPENAI_API_KEY` estÃ¡ configurada
2. Verifique os logs do servidor de aÃ§Ãµes para erros
3. Verifique se o modelo especificado em `actions.py` estÃ¡ disponÃ­vel

### Ollama

Se o Ollama nÃ£o estiver respondendo:

1. Verifique se o serviÃ§o Ollama estÃ¡ em execuÃ§Ã£o
2. Verifique se vocÃª baixou o modelo especificado em `actions.py` (padrÃ£o: llama2)
3. Tente executar `ollama list` para ver os modelos disponÃ­veis

## ğŸ“š Recursos Adicionais

- [DocumentaÃ§Ã£o do Rasa](https://rasa.com/docs/rasa/)
- [DocumentaÃ§Ã£o da API OpenAI](https://platform.openai.com/docs/)
- [DocumentaÃ§Ã£o do Ollama](https://ollama.ai/blog/ollama-is-now-available)

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues ou enviar pull requests.

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a licenÃ§a MIT - veja o arquivo LICENSE para detalhes.

## ğŸ™ Agradecimentos

- [Rasa](https://rasa.com/) pelo incrÃ­vel framework de chatbot
- [OpenAI](https://openai.com/) pela API do ChatGPT
- [Ollama](https://ollama.ai/) por tornar os LLMs acessÃ­veis localmente
